# RecommendationSystemAnalysisandModelling
ğŸ“Š Recommendation System Analysis & Modeling

This project develops and evaluates a Recommendation System using userâ€“item interaction data. It follows the CRISP-DM methodology to provide insights, build models, and generate recommendations across different domains such as e-commerce, content, and services.

ğŸš€ Project Overview

Recommendation systems power modern platforms like Amazon, Netflix, and Spotify, delivering personalized experiences.
This project leverages historical interaction data (events.csv, item_properties, category_tree) to:

Enhance user engagement and retention

Improve conversion rates

Provide diverse and scalable recommendations

ğŸ“‚ Project Structure
ğŸ“ data/
 â”œâ”€â”€ events.csv
 â”œâ”€â”€ item_properties_part1.csv
 â”œâ”€â”€ item_properties_part2.csv
 â””â”€â”€ category_tree.csv

ğŸ“ notebooks/
 â””â”€â”€ RecommendationSystemAnalysisandModelling.ipynb   # Main analysis

ğŸ“ outputs/
 â””â”€â”€ visualizations, metrics, and trained models

ğŸ§  CRISP-DM Methodology
1. Business Understanding

Develop personalized recommendations to improve engagement.

Address multiple use cases: product, content, service.

Balance accuracy vs diversity to avoid repetitive suggestions.

2. Data Understanding

events.csv: user interactions (view, add-to-cart, transaction).

item_properties: metadata (brand, category, availability).

category_tree: hierarchy of item categories.

âœ… Key EDA Insights:

Views dominate interactions â€“ most users only browse, few purchase.

Item popularity is skewed â€“ top 10% of items drive most transactions.

Peak activity occurs evenings & weekends â€“ strong behavioral cycles.

Items cluster together â€“ collaborative filtering surfaces bundles.

Content metadata helps cold-start items â€“ properties like brand/category are crucial.

3. Data Preparation

Filtered meaningful events: view, addtocart, transaction.

Assigned weights (view=1, addtocart=3, transaction=5).

Built userâ€“item interaction matrix with 20k top users & items (for memory safety).

Pivoted item properties into wide-format metadata.

Cleaned missing values in categorical/numeric columns.

4. Modeling

Collaborative Filtering (Itemâ€“Item Similarity):

Constructed sparse userâ€“item matrix.

Applied cosine similarity to compute itemâ€“item relationships.

Generated top-N recommendations per user.

Content-Based Filtering (TF-IDF on item metadata):

Created "bag of properties" text for each item.

Applied TF-IDF + cosine similarity for metadata-driven item matching.

Used for cold-start items with no prior interactions.

5. Evaluation

Evaluated using Precision@K and Recall@K:

Precision@10: 0.1420  
Recall@10:    0.0975


âœ… Interpretation: The recommender captures ~14% precision and ~10% recall at top-10 suggestions.

6. Deployment (Future Work)

Expose via an API for integration into platforms.

Real-time scoring using streaming data (e.g., Kafka + Spark).

Monitor feedback loops to retrain models periodically.

âš™ï¸ Technologies Used

Python 3.11

Pandas / NumPy

Scikit-learn (cosine similarity, TF-IDF)

Matplotlib for visualization

Google Colab for computation

ğŸ“Š Sample Visualization
# Distribution of Event Types
events['event'].value_counts().plot(kind='bar', figsize=(8,5), title="User Event Distribution")

âœ… Recommendations

Boost conversion by retargeting frequent viewers with cart/buy nudges.

Highlight trending items â€“ top 10% items generate most interactions.

Time-based personalization â€“ push recommendations during evening peaks.

Cold-start solution â€“ rely on content metadata for new items.

Hybrid approach â€“ combine collaborative + content-based for robustness.

ğŸ“ Files Included

RecommendationSystemAnalysisandModelling.ipynb â€“ Main notebook (EDA, modeling, evaluation).

events.csv, item_properties_part1.csv, item_properties_part2.csv, category_tree.csv â€“ Raw data.

Visualizations & metrics (outputs).

ğŸ‘©â€ğŸ’» Author

Jessica William

ğŸ“œ License: For educational and analytical purposes only.
